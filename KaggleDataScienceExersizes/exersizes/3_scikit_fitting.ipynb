{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit",
   "display_name": "Python 3.8.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Overfitting is when a model matches the training data almost perfectly, but does poorly in validation and other new data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "When a model fails to capture important distinctions and patterns in the data, so it performs poorly even in training data, that is called underfitting."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![](fitting.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "source": [
    "The max_leaf_nodes argument provides a very sensible way to control overfitting vs underfitting. The more leaves we allow the model to make, the more we move from the underfitting area in the above graph to the overfitting area."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "melbourne_file_path = '/Users/onsightimac21/Documents/JupyterNotebooksForDataScience/KaggleDataScienceExersizes/data/melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "\n",
    "filtered_melbourne_data = melbourne_data.dropna(axis=0)\n",
    "y = filtered_melbourne_data.Price\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n",
    "                        'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "X = filtered_melbourne_data[melbourne_features]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into training and validation data, for both features and target\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Max leaf nodes: 5  \t\t Mean Absolute Error:  347380\nMax leaf nodes: 50  \t\t Mean Absolute Error:  258171\nMax leaf nodes: 500  \t\t Mean Absolute Error:  243495\nMax leaf nodes: 5000  \t\t Mean Absolute Error:  254983\n"
     ]
    }
   ],
   "source": [
    "# compare MAE with differing values of max_leaf_nodes\n",
    "for max_leaf_nodes in [5, 50, 500, 5000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))"
   ]
  },
  {
   "source": [
    "Of the options listed, 500 is the optimal number of leaves."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Overfitting: capturing spurious patterns that won't recur in the future, leading to less accurate predictions, or\n",
    "Underfitting: failing to capture relevant patterns, again leading to less accurate predictions.\n",
    "We use validation data, which isn't used in model training, to measure a candidate model's accuracy. This lets us try many candidate models and keep the best one."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}